{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVc7qnxCmKEA",
        "outputId": "89660eb7-d620-4137-a0d9-1312a3c0c4c2"
      },
      "outputs": [],
      "source": [
        "# Running this script will install the required dependencies for the notebook if running in Colab\n",
        "\n",
        "!wget https://setup.johnsnowlabs.com/colab.sh -O - | bash /dev/stdin -p 3.4.1 -s 5.1.2 -g"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "path = \"./data\"\n",
        "df_amazon_train = pd.read_csv(f\"{path}/train.csv\", index_col=0)\n",
        "df_amazon_test = pd.read_csv(f\"{path}/test.csv\", index_col=0)\n",
        "df_amazon_validation = pd.read_csv(f\"{path}/validation.csv\", index_col=0)\n",
        "df_turkish = pd.read_csv(f\"{path}/hb.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_turkish_sample = df_turkish.sample(210000, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_amazon = df_amazon_train[[\"review_body\", \"language\", \"stars\"]]\n",
        "df_turkish_sample = df_turkish_sample[[\"Rating (Star)\", \"Review\"]]\n",
        "df_turkish_sample.rename(\n",
        "    columns={\"Review\": \"review_body\", \"Rating (Star)\": \"stars\"}, inplace=True\n",
        ")\n",
        "df_turkish_sample[\"language\"] = \"tr\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "consolidated_df = pd.concat([df_amazon, df_turkish_sample], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "consolidated_df[\"review_body\"] = consolidated_df[\"review_body\"].str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "consolidated_df.drop(\n",
        "    consolidated_df[\n",
        "        consolidated_df[\"language\"].isin([\"ja\", \"zh\", \"de\", \"fr\", \"es\", \"tr\"])\n",
        "    ].index,\n",
        "    inplace=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(consolidated_df, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df.to_csv(f\"{path}/final_training.csv\", index=False)\n",
        "test_df.to_csv(f\"{path}/final_test.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jHp7HIoZiR5"
      },
      "source": [
        "# Train Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sparknlp\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from pyspark.ml import Pipeline\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark = sparknlp.start(gpu=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvs989M2jtg8"
      },
      "outputs": [],
      "source": [
        "trainDataset = spark.read.option(\"header\", True).csv(\"./consolidated.csv\", escape='\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y72s0L_wn_qU",
        "outputId": "be24ce10-9846-4512-f962-fd44c82cc5dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lemma_antbnc download started this may take some time.\n",
            "Approximate size to download 907.6 KB\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "document_assembler = (\n",
        "    DocumentAssembler().setInputCol(\"review_body\").setOutputCol(\"document\")\n",
        ")\n",
        "\n",
        "tokenizer = Tokenizer().setInputCols([\"document\"]).setOutputCol(\"token\")\n",
        "\n",
        "normalizer = Normalizer().setInputCols([\"token\"]).setOutputCol(\"normalized\")\n",
        "\n",
        "stopwords_cleaner = (\n",
        "    StopWordsCleaner()\n",
        "    .setInputCols(\"normalized\")\n",
        "    .setOutputCol(\"cleanTokens\")\n",
        "    .setCaseSensitive(False)\n",
        ")\n",
        "\n",
        "lemma = (\n",
        "    LemmatizerModel.pretrained(\"lemma_antbnc\")\n",
        "    .setInputCols([\"cleanTokens\"])\n",
        "    .setOutputCol(\"lemma\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjos1cR9oBNx",
        "outputId": "1bf068b9-1b2e-49d0-c829-ab5391b8876d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "glove_100d download started this may take some time.\n",
            "Approximate size to download 145.3 MB\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "glove_embeddings = (\n",
        "    WordEmbeddingsModel()\n",
        "    .pretrained()\n",
        "    .setInputCols([\"document\", \"lemma\"])\n",
        "    .setOutputCol(\"embeddings\")\n",
        "    .setCaseSensitive(False)\n",
        ")\n",
        "\n",
        "embeddingsSentence = (\n",
        "    SentenceEmbeddings()\n",
        "    .setInputCols([\"document\", \"embeddings\"])\n",
        "    .setOutputCol(\"sentence_embeddings\")\n",
        "    .setPoolingStrategy(\"AVERAGE\")\n",
        ")\n",
        "\n",
        "classsifierdl = (\n",
        "    ClassifierDLApproach()\n",
        "    .setInputCols([\"sentence_embeddings\"])\n",
        "    .setOutputCol(\"class\")\n",
        "    .setLabelColumn(\"stars\")\n",
        "    .setMaxEpochs(10)\n",
        "    .setLr(1e-3)\n",
        "    .setValidationSplit(1e-1)\n",
        "    .setEvaluationLogExtended(True)\n",
        "    .setEnableOutputLogs(True)\n",
        ")\n",
        "\n",
        "train_pipeline = Pipeline(\n",
        "    stages=[\n",
        "        document_assembler,\n",
        "        tokenizer,\n",
        "        normalizer,\n",
        "        stopwords_cleaner,\n",
        "        lemma,\n",
        "        glove_embeddings,\n",
        "        embeddingsSentence,\n",
        "        classsifierdl,\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKGfUIhvo34u",
        "outputId": "de3c2fa1-cb10-4df0-8d49-97b22133253a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 3.18 s, sys: 316 ms, total: 3.49 s\n",
            "Wall time: 9min 36s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "train_pipeline_model = train_pipeline.fit(trainDataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkpGn4Hso8zz",
        "outputId": "6982992c-6b2b-4942-aa24-d4eb2170cf4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label        tp\t fp\t fn\t prec\t rec\t f1\n",
            "4            1366\t 2416\t 9264\t 0.36118457\t 0.12850423\t 0.18956424\n",
            "5            14240\t 10502\t 2981\t 0.5755396\t 0.8268974\t 0.6786932\n",
            "1            4102\t 5271\t 2967\t 0.43764004\t 0.5802801\t 0.4989661\n",
            "2            2657\t 6504\t 4515\t 0.29003385\t 0.3704685\t 0.32535362\n",
            "3            1163\t 2179\t 7145\t 0.34799522\t 0.13998556\t 0.19965667\n",
            "tp: 23528 fp: 26872 fn: 26872 labels: 5\n",
            "Macro-average\t prec: 0.40247864, rec: 0.4092272, f1: 0.40582487\n",
            "Micro-average\t prec: 0.4668254, recall: 0.4668254, f1: 0.4668254\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "log_file_name = os.listdir(\"/root/annotator_logs\")[0]\n",
        "\n",
        "with open(\"/root/annotator_logs/\" + log_file_name, \"r\") as log_file:\n",
        "    print(log_file.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owsY6vArdr1L",
        "outputId": "ccaa2200-f19a-499b-b6aa-a0b27f088714"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 44\n",
            "-rw-r--r-- 1 root root 1496 Apr  2 10:58 ClassifierDLApproach_73b794d1720d.log\n",
            "-rw-r--r-- 1 root root  535 Apr  2 10:58 ClassifierMetrics_109aa4693c3f.log\n",
            "-rw-r--r-- 1 root root  533 Apr  2 10:55 ClassifierMetrics_125dbfc9bbcd.log\n",
            "-rw-r--r-- 1 root root  537 Apr  2 10:56 ClassifierMetrics_18ecfb27ed22.log\n",
            "-rw-r--r-- 1 root root  539 Apr  2 10:54 ClassifierMetrics_225cef80dc6c.log\n",
            "-rw-r--r-- 1 root root  536 Apr  2 10:55 ClassifierMetrics_23b8273bb4d4.log\n",
            "-rw-r--r-- 1 root root  531 Apr  2 10:54 ClassifierMetrics_4214345dcedf.log\n",
            "-rw-r--r-- 1 root root  534 Apr  2 10:58 ClassifierMetrics_7745baae85b9.log\n",
            "-rw-r--r-- 1 root root  534 Apr  2 10:53 ClassifierMetrics_9a42e07926b4.log\n",
            "-rw-r--r-- 1 root root  539 Apr  2 10:57 ClassifierMetrics_a54d07433560.log\n",
            "-rw-r--r-- 1 root root  534 Apr  2 10:57 ClassifierMetrics_b6155e43f57a.log\n"
          ]
        }
      ],
      "source": [
        "!cd ~/annotator_logs && ls -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlS2aDiad2cC",
        "outputId": "8128e357-20ea-408b-d716-7e461e20d75d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training started - epochs: 10 - learning_rate: 0.001 - batch_size: 64 - training_examples: 453600 - classes: 5\n",
            "Epoch 0/10 - 37.60s - loss: 10175.209 - acc: 0.45098862 - batches: 7088\n",
            "Quality on validation dataset (10.0%), validation examples = 50400\n",
            "Epoch 1/10 - 35.92s - loss: 10079.269 - acc: 0.46794528 - batches: 7088\n",
            "Quality on validation dataset (10.0%), validation examples = 50400\n",
            "Epoch 2/10 - 35.64s - loss: 10053.937 - acc: 0.472573 - batches: 7088\n",
            "Quality on validation dataset (10.0%), validation examples = 50400\n",
            "Epoch 3/10 - 35.65s - loss: 10039.82 - acc: 0.47564644 - batches: 7088\n",
            "Quality on validation dataset (10.0%), validation examples = 50400\n",
            "Epoch 4/10 - 35.43s - loss: 10029.037 - acc: 0.47776958 - batches: 7088\n",
            "Quality on validation dataset (10.0%), validation examples = 50400\n",
            "Epoch 5/10 - 35.13s - loss: 10020.801 - acc: 0.47936362 - batches: 7088\n",
            "Quality on validation dataset (10.0%), validation examples = 50400\n",
            "Epoch 6/10 - 35.44s - loss: 10014.198 - acc: 0.4808761 - batches: 7088\n",
            "Quality on validation dataset (10.0%), validation examples = 50400\n",
            "Epoch 7/10 - 36.05s - loss: 10008.565 - acc: 0.48202035 - batches: 7088\n",
            "Quality on validation dataset (10.0%), validation examples = 50400\n",
            "Epoch 8/10 - 35.87s - loss: 10003.689 - acc: 0.48303452 - batches: 7088\n",
            "Quality on validation dataset (10.0%), validation examples = 50400\n",
            "Epoch 9/10 - 35.71s - loss: 9999.206 - acc: 0.48388335 - batches: 7088\n",
            "Quality on validation dataset (10.0%), validation examples = 50400\n"
          ]
        }
      ],
      "source": [
        "!cat ~/annotator_logs/ClassifierDLApproach_73b794d1720d.log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FY-0Fj5fRvHM"
      },
      "outputs": [],
      "source": [
        "train_pipeline_model.stages[-1].write().overwrite().save(f\"{path}/model_weights\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDJaW4CcakDh"
      },
      "source": [
        "# Inference Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1P-GR3Mpscy"
      },
      "outputs": [],
      "source": [
        "testDataset = spark.read.option(\"header\", True).csv(\n",
        "    f\"{path}/final_test.csv\", escape='\"'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlWUcZBuSLG1",
        "outputId": "14f968c2-72ac-47ab-b6d1-b16f5dc496be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lemma_antbnc download started this may take some time.\n",
            "Approximate size to download 907.6 KB\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "document_assembler = (\n",
        "    DocumentAssembler().setInputCol(\"review_body\").setOutputCol(\"document\")\n",
        ")\n",
        "\n",
        "tokenizer = Tokenizer().setInputCols([\"document\"]).setOutputCol(\"token\")\n",
        "\n",
        "normalizer = Normalizer().setInputCols([\"token\"]).setOutputCol(\"normalized\")\n",
        "\n",
        "stopwords_cleaner = (\n",
        "    StopWordsCleaner()\n",
        "    .setInputCols(\"normalized\")\n",
        "    .setOutputCol(\"cleanTokens\")\n",
        "    .setCaseSensitive(False)\n",
        ")\n",
        "\n",
        "lemma = (\n",
        "    LemmatizerModel.pretrained(\"lemma_antbnc\")\n",
        "    .setInputCols([\"cleanTokens\"])\n",
        "    .setOutputCol(\"lemma\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8vKWpHOSB8G",
        "outputId": "13956db0-8e10-4aa6-fbdd-974586da7eaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "glove_100d download started this may take some time.\n",
            "Approximate size to download 145.3 MB\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "glove_embeddings = (\n",
        "    WordEmbeddingsModel()\n",
        "    .pretrained()\n",
        "    .setInputCols([\"document\", \"lemma\"])\n",
        "    .setOutputCol(\"embeddings\")\n",
        "    .setCaseSensitive(False)\n",
        ")\n",
        "\n",
        "embeddingsSentence = (\n",
        "    SentenceEmbeddings()\n",
        "    .setInputCols([\"document\", \"embeddings\"])\n",
        "    .setOutputCol(\"sentence_embeddings\")\n",
        "    .setPoolingStrategy(\"AVERAGE\")\n",
        ")\n",
        "\n",
        "classsifierdl = (\n",
        "    ClassifierDLModel.load(\"./model_weights\")\n",
        "    .setInputCols([\"sentence_embeddings\"])\n",
        "    .setOutputCol(\"class\")\n",
        ")\n",
        "\n",
        "test_pipeline = Pipeline(\n",
        "    stages=[\n",
        "        document_assembler,\n",
        "        tokenizer,\n",
        "        normalizer,\n",
        "        stopwords_cleaner,\n",
        "        lemma,\n",
        "        glove_embeddings,\n",
        "        embeddingsSentence,\n",
        "        classsifierdl,\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjFpUurwp3n5"
      },
      "outputs": [],
      "source": [
        "preds = test_pipeline.fit(testDataset).transform(testDataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6ufp8Nqp-ti"
      },
      "outputs": [],
      "source": [
        "preds_df = preds.select(\"stars\", \"review_body\", \"class.result\").toPandas()\n",
        "preds_df[\"result\"] = preds_df[\"result\"].apply(lambda x: x[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcsnSDPOqO8s",
        "outputId": "b3b7e649-7e71-46c9-f1c6-a650dfc233fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.48      0.57      0.52     17699\n",
            "           2       0.32      0.30      0.31     17690\n",
            "           3       0.34      0.22      0.27     21240\n",
            "           4       0.37      0.18      0.24     26434\n",
            "           5       0.58      0.83      0.68     42937\n",
            "\n",
            "    accuracy                           0.48    126000\n",
            "   macro avg       0.42      0.42      0.40    126000\n",
            "weighted avg       0.44      0.48      0.44    126000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(preds_df[\"stars\"], preds_df[\"result\"]))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
